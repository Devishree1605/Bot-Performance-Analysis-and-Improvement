{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJxqYPAOPzSA"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder.appName(\"UserStory8_IntentClassification\").getOrCreate()\n",
        "\n",
        "data_path = r'/content/trading_bot_dataset_with_user_profiles1.csv'\n",
        "df = spark.read.csv(data_path, header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0Eo0kyWQMOI",
        "outputId": "9965e6e8-c4ef-48d7-be2b-1aadfaa56c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Interaction ID: integer (nullable = true)\n",
            " |-- Timestamp: timestamp (nullable = true)\n",
            " |-- User Query: string (nullable = true)\n",
            " |-- Intent Detected: string (nullable = true)\n",
            " |-- Bot Response: string (nullable = true)\n",
            " |-- Response Time (ms): integer (nullable = true)\n",
            " |-- Prediction Accuracy (%): integer (nullable = true)\n",
            " |-- Entity Extraction Accuracy (%): integer (nullable = true)\n",
            " |-- User Sentiment: string (nullable = true)\n",
            " |-- User Feedback: string (nullable = true)\n",
            " |-- Conversation Success: string (nullable = true)\n",
            " |-- User ID: string (nullable = true)\n",
            " |-- User Type: string (nullable = true)\n",
            " |-- Region: string (nullable = true)\n",
            " |-- Device Type: string (nullable = true)\n",
            " |-- Account Age (months): integer (nullable = true)\n",
            " |-- Is Premium: boolean (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, lower, col, lit, avg\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"SentimentClassifier\").getOrCreate()\n",
        "\n",
        "# Replace this with your actual CSV file path on your machine\n",
        "csv_path = r'/content/trading_bot_dataset_with_user_profiles1.csv'\n",
        "  # Windows example (use 'file://' prefix)\n",
        "\n",
        "# Load data from CSV\n",
        "# Assumes CSV has columns: User Feedback, User Sentiment, User ID, Interaction ID\n",
        "raw_df = spark.read.option(\"header\", True).csv(csv_path)\n",
        "\n",
        "# Optional: show schema and few rows to verify loading worked\n",
        "raw_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LNiw6oHQQ8H",
        "outputId": "edd2f80e-f2b5-4977-e2fa-ef309877c77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Interaction ID: string (nullable = true)\n",
            " |-- Timestamp: string (nullable = true)\n",
            " |-- User Query: string (nullable = true)\n",
            " |-- Intent Detected: string (nullable = true)\n",
            " |-- Bot Response: string (nullable = true)\n",
            " |-- Response Time (ms): string (nullable = true)\n",
            " |-- Prediction Accuracy (%): string (nullable = true)\n",
            " |-- Entity Extraction Accuracy (%): string (nullable = true)\n",
            " |-- User Sentiment: string (nullable = true)\n",
            " |-- User Feedback: string (nullable = true)\n",
            " |-- Conversation Success: string (nullable = true)\n",
            " |-- User ID: string (nullable = true)\n",
            " |-- User Type: string (nullable = true)\n",
            " |-- Region: string (nullable = true)\n",
            " |-- Device Type: string (nullable = true)\n",
            " |-- Account Age (months): string (nullable = true)\n",
            " |-- Is Premium: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqjuledAQeaA",
        "outputId": "9d096488-6c07-425c-e35d-9ed0d2eb93e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------------+----------------------------------+----------------+-------------------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------+-------------+-------------+-----------+--------------------+----------+\n",
            "|Interaction ID|Timestamp       |User Query                        |Intent Detected |Bot Response                   |Response Time (ms)|Prediction Accuracy (%)|Entity Extraction Accuracy (%)|User Sentiment|User Feedback    |Conversation Success|User ID|User Type    |Region       |Device Type|Account Age (months)|Is Premium|\n",
            "+--------------+----------------+----------------------------------+----------------+-------------------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------+-------------+-------------+-----------+--------------------+----------+\n",
            "|1             |2020-01-28 14:41|What is your prediction for Bonds?|Financial Advice|Bonds remain a safe haven.     |150               |95                     |90                            |Positive      |Helpful          |Successful          |U10166 |Retail       |Asia         |Tablet     |43                  |False     |\n",
            "|2             |2020-11-26 11:59|What is your prediction for Forex?|Price Check     |Forex markets favor USD today. |155               |94                     |91                            |Negative      |Needs improvement|Failed              |U10030 |Retail       |South America|Desktop    |9                   |False     |\n",
            "|3             |2021-09-06 17:10|Any news on Gold?                 |Stock Prediction|Investors are flocking to Gold.|160               |93                     |92                            |Negative      |Needs improvement|Failed              |U10253 |Institutional|Asia         |Mobile     |4                   |True      |\n",
            "|4             |2022-09-14 16:14|Should I buy or sell WTI?         |Strategy Advice |WTI is showing high volatility.|165               |92                     |93                            |Neutral       |Needs improvement|Failed              |U10255 |Retail       |Europe       |Mobile     |49                  |False     |\n",
            "|5             |2023-11-06 11:40|What's the trend with Tesla?      |Strategy Advice |Tesla shows bullish signs.     |170               |91                     |94                            |Negative      |Needs improvement|Failed              |U10085 |Retail       |North America|Desktop    |25                  |False     |\n",
            "+--------------+----------------+----------------------------------+----------------+-------------------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------+-------------+-------------+-----------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now continue with the same pipeline steps:\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"User Feedback\", outputCol=\"words\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
      ],
      "metadata": {
        "id": "qbUSW-kvQirr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf])\n",
        "enriched_df = feature_pipeline.fit(raw_df).transform(raw_df)"
      ],
      "metadata": {
        "id": "ihLsXdoWR0u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enriched_df = enriched_df.withColumn(\n",
        "    \"label\",\n",
        "    when(lower(col(\"User Sentiment\")) == \"positive\", 2.0)\n",
        "    .when(lower(col(\"User Sentiment\")) == \"neutral\", 1.0)\n",
        "    .otherwise(0.0)\n",
        ")"
      ],
      "metadata": {
        "id": "VGl3fgWDR5vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Select only the 'features' and 'label' columns for model training\n",
        "training_data = enriched_df.select(\"features\", \"label\")\n",
        "\n",
        "print(\"=== Training data (features and label) sample ===\")\n",
        "training_data.show(5, truncate=False)  # Show first 5 rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H95sx1DR-iV",
        "outputId": "c204a520-8d15-488a-a104-4780e49121fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Training data (features and label) sample ===\n",
            "+--------------------------------------------------------+-----+\n",
            "|features                                                |label|\n",
            "+--------------------------------------------------------+-----+\n",
            "|(1000,[286],[0.5101598447800131])                       |2.0  |\n",
            "|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |\n",
            "|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |\n",
            "|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|1.0  |\n",
            "|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |\n",
            "+--------------------------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Logistic Regression classifier for multi-class sentiment classification\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
        "# Train the Logistic Regression model on the training data\n",
        "model = lr.fit(training_data)\n",
        "# Use the trained model to predict sentiment on the full enriched dataset\n",
        "predictions = model.transform(enriched_df)\n",
        "print(\"=== Predictions sample ===\")\n",
        "predictions.select(\"User Feedback\", \"User Sentiment\", \"features\", \"label\", \"prediction\", \"probability\").show(5, truncate=False)\n",
        "# Add a new column 'Adaptive_Action' based on predicted sentiment class:\n",
        "# If predicted class is 0 (negative), action = \"Simplify Response\"\n",
        "# If predicted class is 1 (neutral), action = \"Neutral - Monitor\"\n",
        "# Otherwise (class 2 = positive), action = \"No Change\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_IfssBVSCCL",
        "outputId": "220a1d01-f5ab-4518-841f-1c34ee12c3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Predictions sample ===\n",
            "+-----------------+--------------+--------------------------------------------------------+-----+----------+----------------------------------------------------------------+\n",
            "|User Feedback    |User Sentiment|features                                                |label|prediction|probability                                                     |\n",
            "+-----------------+--------------+--------------------------------------------------------+-----+----------+----------------------------------------------------------------+\n",
            "|Helpful          |Positive      |(1000,[286],[0.5101598447800131])                       |2.0  |2.0       |[1.3993849606908003E-4,1.1092330660680896E-4,0.9997491381973241]|\n",
            "|Needs improvement|Negative      |(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |0.0       |[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]   |\n",
            "|Needs improvement|Negative      |(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |0.0       |[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]   |\n",
            "|Needs improvement|Neutral       |(1000,[678,740],[0.9147933520086514,0.9147933520086514])|1.0  |0.0       |[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]   |\n",
            "|Needs improvement|Negative      |(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |0.0       |[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]   |\n",
            "+-----------------+--------------+--------------------------------------------------------+-----+----------+----------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adaptive_actions = predictions.withColumn(\n",
        "    \"Adaptive_Action\",\n",
        "    when(col(\"prediction\") == 0.0, lit(\"Simplify Response\"))\n",
        "    .when(col(\"prediction\") == 1.0, lit(\"Neutral - Monitor\"))\n",
        "    .otherwise(lit(\"No Change\"))\n",
        ")\n",
        "print(\"=== After adding Adaptive_Action column ===\")\n",
        "adaptive_actions.select(\"User Feedback\", \"prediction\", \"Adaptive_Action\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GExZuyCjSFTU",
        "outputId": "58c01262-6ce5-4a51-f20c-ad61e00cb75c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== After adding Adaptive_Action column ===\n",
            "+-----------------+----------+-----------------+\n",
            "|User Feedback    |prediction|Adaptive_Action  |\n",
            "+-----------------+----------+-----------------+\n",
            "|Helpful          |2.0       |No Change        |\n",
            "|Needs improvement|0.0       |Simplify Response|\n",
            "|Needs improvement|0.0       |Simplify Response|\n",
            "|Needs improvement|0.0       |Simplify Response|\n",
            "|Needs improvement|0.0       |Simplify Response|\n",
            "+-----------------+----------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute average predicted sentiment per User ID\n",
        "user_sentiment_avg = adaptive_actions.groupBy(\"User ID\").agg(avg(\"prediction\").alias(\"Avg_Sentiment\"))\n",
        "print(\"=== Average sentiment per user ===\")\n",
        "user_sentiment_avg.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zpBGgH6SIl_",
        "outputId": "b586b1ef-aedd-4111-eea6-ad1782ef7f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Average sentiment per user ===\n",
            "+-------+------------------+\n",
            "|User ID|Avg_Sentiment     |\n",
            "+-------+------------------+\n",
            "|U10088 |1.0               |\n",
            "|U10023 |0.8               |\n",
            "|U10165 |0.75              |\n",
            "|U10086 |1.6666666666666667|\n",
            "|U10261 |0.6666666666666666|\n",
            "+-------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flag users for escalation based on average sentiment\n",
        "escalation_flags = user_sentiment_avg.withColumn(\n",
        "    \"Auto_Escalate\",\n",
        "    when(col(\"Avg_Sentiment\") < 0.5, lit(True)).otherwise(lit(False))\n",
        ")\n",
        "print(\"=== Escalation flags for users ===\")\n",
        "escalation_flags.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jisZVAaSLdb",
        "outputId": "0ba5feca-0b77-44d2-8922-911d9cc3234d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Escalation flags for users ===\n",
            "+-------+------------------+-------------+\n",
            "|User ID|Avg_Sentiment     |Auto_Escalate|\n",
            "+-------+------------------+-------------+\n",
            "|U10088 |1.0               |false        |\n",
            "|U10023 |0.8               |false        |\n",
            "|U10165 |0.75              |false        |\n",
            "|U10086 |1.6666666666666667|false        |\n",
            "|U10261 |0.6666666666666666|false        |\n",
            "+-------+------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join escalation flags back to the session-level data\n",
        "final_output = adaptive_actions.join(escalation_flags, on=\"User ID\", how=\"left\")\n",
        "print(\"=== Final output with escalation flags ===\")\n",
        "final_output.select(\n",
        "    \"Interaction ID\", \"User ID\", \"User Feedback\", \"User Sentiment\", \"prediction\", \"Adaptive_Action\", \"Auto_Escalate\"\n",
        ").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP6xa6hYSN_y",
        "outputId": "028859e7-f188-4ba4-c2ae-1af1e9c58a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Final output with escalation flags ===\n",
            "+--------------+-------+-----------------+--------------+----------+-----------------+-------------+\n",
            "|Interaction ID|User ID|User Feedback    |User Sentiment|prediction|Adaptive_Action  |Auto_Escalate|\n",
            "+--------------+-------+-----------------+--------------+----------+-----------------+-------------+\n",
            "|1             |U10166 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|2             |U10030 |Needs improvement|Negative      |0.0       |Simplify Response|false        |\n",
            "|3             |U10253 |Needs improvement|Negative      |0.0       |Simplify Response|false        |\n",
            "|4             |U10255 |Needs improvement|Neutral       |0.0       |Simplify Response|false        |\n",
            "|5             |U10085 |Needs improvement|Negative      |0.0       |Simplify Response|false        |\n",
            "+--------------+-------+-----------------+--------------+----------+-----------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the escalation flags back to the session-level data on \"User ID\"\n",
        "final_output = adaptive_actions.join(escalation_flags, on=\"User ID\", how=\"left\")\n",
        "final_output.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWfxfas1SSOT",
        "outputId": "a29acfd8-5918-4cb8-c195-fc35d6caea90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------+----------------+--------------------+--------------------+--------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------------+-------------+-----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+-----------------+------------------+-------------+\n",
            "|User ID|Interaction ID|       Timestamp|          User Query|     Intent Detected|        Bot Response|Response Time (ms)|Prediction Accuracy (%)|Entity Extraction Accuracy (%)|User Sentiment|    User Feedback|Conversation Success|    User Type|       Region|Device Type|Account Age (months)|Is Premium|               words|            filtered|         rawFeatures|            features|label|       rawPrediction|         probability|prediction|  Adaptive_Action|     Avg_Sentiment|Auto_Escalate|\n",
            "+-------+--------------+----------------+--------------------+--------------------+--------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------------+-------------+-----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+-----------------+------------------+-------------+\n",
            "| U10166|             1|2020-01-28 14:41|What is your pred...|    Financial Advice|Bonds remain a sa...|               150|                     95|                            90|      Positive|          Helpful|          Successful|       Retail|         Asia|     Tablet|                  43|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|\n",
            "| U10030|             2|2020-11-26 11:59|What is your pred...|         Price Check|Forex markets fav...|               155|                     94|                            91|      Negative|Needs improvement|              Failed|       Retail|South America|    Desktop|                   9|     False|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  0.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|0.6666666666666666|        false|\n",
            "| U10253|             3|2021-09-06 17:10|   Any news on Gold?|    Stock Prediction|Investors are flo...|               160|                     93|                            92|      Negative|Needs improvement|              Failed|Institutional|         Asia|     Mobile|                   4|      True|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  0.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|0.6666666666666666|        false|\n",
            "| U10255|             4|2022-09-14 16:14|Should I buy or s...|     Strategy Advice|WTI is showing hi...|               165|                     92|                            93|       Neutral|Needs improvement|              Failed|       Retail|       Europe|     Mobile|                  49|     False|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  1.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|               0.5|        false|\n",
            "| U10085|             5|2023-11-06 11:40|What's the trend ...|     Strategy Advice|Tesla shows bulli...|               170|                     91|                            94|      Negative|Needs improvement|              Failed|       Retail|North America|    Desktop|                  25|     False|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  0.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|1.3333333333333333|        false|\n",
            "| U10228|             6|2023-07-01 12:28|Should I buy or s...|      Forex Analysis|Crypto markets sh...|               175|                     90|                            90|      Positive|          Helpful|          Successful|Institutional|North America|     Mobile|                  51|      True|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               1.5|        false|\n",
            "| U10081|             7|2024-07-13 09:45|    Analysis of Oil?|         Price Check|Oil shows demand ...|               180|                     89|                            91|      Positive|          Helpful|          Successful|       Retail|         Asia|    Desktop|                  44|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|\n",
            "| U10271|             8|2021-04-09 10:36|What's the price ...|Cryptocurrency Up...|GBP trends show m...|               185|                     88|                            92|      Positive|          Helpful|          Successful|Institutional|       Europe|     Tablet|                  37|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|\n",
            "| U10044|             9|2020-09-06 14:20|Should I buy or s...|     Market Analysis|ETH is showing a ...|               190|                     87|                            93|      Positive|          Helpful|          Successful|Institutional|       Africa|     Tablet|                  55|      True|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               1.2|        false|\n",
            "| U10131|            10|2021-08-04 13:42|Give me an update...| Investment Planning|USD is strengthen...|               195|                     86|                            94|      Positive|          Helpful|          Successful|       Retail|       Europe|     Mobile|                  57|      True|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               1.6|        false|\n",
            "| U10283|            11|2023-09-21 14:38|What's the price ...|         Price Check|Tesla shows bulli...|               150|                     95|                            90|      Positive|          Helpful|          Successful|       Retail|       Europe|     Mobile|                  55|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|1.3333333333333333|        false|\n",
            "| U10066|            12|2023-10-13 10:22|What is your pred...|    Stock Prediction| USD remains stable.|               155|                     94|                            91|       Neutral|Needs improvement|              Failed|Institutional|       Africa|     Mobile|                  54|     False|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  1.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|               1.0|        false|\n",
            "| U10135|            13|2022-08-20 11:52|What's the trend ...|     Strategy Advice|Oil prices are ri...|               160|                     93|                            92|      Positive|          Helpful|          Successful|Institutional|       Europe|     Mobile|                  23|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|\n",
            "| U10104|            14|2022-10-19 10:43|What's your take ...|           Buy Order|GOOGL stock is sl...|               165|                     92|                            93|      Positive|          Helpful|          Successful|       Retail|       Europe|     Mobile|                  27|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               1.0|        false|\n",
            "| U10008|            15|2021-06-04 12:19|Market outlook fo...|      Forex Analysis|ETH is showing a ...|               170|                     91|                            94|      Negative|Needs improvement|              Failed|Institutional|         Asia|    Desktop|                  37|      True|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  0.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|               1.0|        false|\n",
            "| U10015|            16|2020-03-12 11:32|Market outlook fo...|   Future Investment|NASDAQ shows inve...|               175|                     90|                            90|      Positive|          Helpful|          Successful|       Retail|       Europe|     Mobile|                  37|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|\n",
            "| U10150|            17|2023-07-20 11:36|What's the trend ...|    Stock Prediction|Crypto markets sh...|               180|                     89|                            91|      Negative|Needs improvement|              Failed|       Retail|North America|     Mobile|                  36|      True|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  0.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|1.3333333333333333|        false|\n",
            "| U10070|            18|2023-07-06 16:40|Market outlook fo...|          Sell Order|Oil shows demand ...|               185|                     88|                            92|      Positive|          Helpful|          Successful|Institutional|North America|     Tablet|                  56|      True|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|\n",
            "| U10298|            19|2024-12-21 11:35|Market outlook fo...|     Market Analysis|GOOGL remains a s...|               190|                     87|                            93|      Positive|          Helpful|          Successful|       Retail|         Asia|     Tablet|                  53|      True|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|0.6666666666666666|        false|\n",
            "| U10112|            20|2021-08-10 11:11|What's the trend ...|    Stock Prediction|MSFT outlook is p...|               195|                     86|                            94|      Positive|          Helpful|          Successful|       Retail|North America|     Mobile|                  14|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               1.5|        false|\n",
            "+-------+--------------+----------------+--------------------+--------------------+--------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------------+-------------+-----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+-----------------+------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display final actionable insights for each interaction/session\n",
        "final_output.select(\n",
        "    \"Interaction ID\", \"User ID\", \"User Feedback\", \"User Sentiment\", \"prediction\", \"Adaptive_Action\", \"Auto_Escalate\"\n",
        ").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SaX3BuJSUx8",
        "outputId": "5aea51ce-dd8d-45c3-a90d-d7b0754efb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------+-----------------+--------------+----------+-----------------+-------------+\n",
            "|Interaction ID|User ID|User Feedback    |User Sentiment|prediction|Adaptive_Action  |Auto_Escalate|\n",
            "+--------------+-------+-----------------+--------------+----------+-----------------+-------------+\n",
            "|1             |U10166 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|2             |U10030 |Needs improvement|Negative      |0.0       |Simplify Response|false        |\n",
            "|3             |U10253 |Needs improvement|Negative      |0.0       |Simplify Response|false        |\n",
            "|4             |U10255 |Needs improvement|Neutral       |0.0       |Simplify Response|false        |\n",
            "|5             |U10085 |Needs improvement|Negative      |0.0       |Simplify Response|false        |\n",
            "|6             |U10228 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|7             |U10081 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|8             |U10271 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|9             |U10044 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|10            |U10131 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|11            |U10283 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|12            |U10066 |Needs improvement|Neutral       |0.0       |Simplify Response|false        |\n",
            "|13            |U10135 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|14            |U10104 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|15            |U10008 |Needs improvement|Negative      |0.0       |Simplify Response|false        |\n",
            "|16            |U10015 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|17            |U10150 |Needs improvement|Negative      |0.0       |Simplify Response|false        |\n",
            "|18            |U10070 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|19            |U10298 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "|20            |U10112 |Helpful          |Positive      |2.0       |No Change        |false        |\n",
            "+--------------+-------+-----------------+--------------+----------+-----------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_output.select(\n",
        "    \"Interaction ID\", \"User ID\", \"User Feedback\", \"User Sentiment\", \"prediction\", \"Adaptive_Action\", \"Auto_Escalate\"\n",
        ").filter(col(\"Auto_Escalate\") == True).show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I_oZ_umSgSF",
        "outputId": "c44ba8f7-72d1-4fbc-c57e-d5b24e71b9e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------+-----------------+--------------+----------+-----------------+-------------+\n",
            "|Interaction ID|User ID|User Feedback    |User Sentiment|prediction|Adaptive_Action  |Auto_Escalate|\n",
            "+--------------+-------+-----------------+--------------+----------+-----------------+-------------+\n",
            "|22            |U10279 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|28            |U10248 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|83            |U10233 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|86            |U10189 |Needs improvement|Neutral       |0.0       |Simplify Response|true         |\n",
            "|94            |U10012 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|116           |U10155 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|120           |U10180 |Needs improvement|Neutral       |0.0       |Simplify Response|true         |\n",
            "|127           |U10180 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|131           |U10012 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|143           |U10285 |Needs improvement|Neutral       |0.0       |Simplify Response|true         |\n",
            "|149           |U10233 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|166           |U10116 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|180           |U10026 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|187           |U10267 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|220           |U10054 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|231           |U10282 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|239           |U10160 |Needs improvement|Neutral       |0.0       |Simplify Response|true         |\n",
            "|242           |U10282 |Helpful          |Positive      |2.0       |No Change        |true         |\n",
            "|247           |U10252 |Needs improvement|Negative      |0.0       |Simplify Response|true         |\n",
            "|266           |U10021 |Needs improvement|Neutral       |0.0       |Simplify Response|true         |\n",
            "+--------------+-------+-----------------+--------------+----------+-----------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_output = final_output.withColumn(\n",
        "        \"Session_Escalate\",\n",
        "        when(col(\"prediction\") <= 1.0, lit(True)).otherwise(lit(False))\n",
        "    )\n",
        "final_output.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV7-xMV1Si2k",
        "outputId": "c2761eae-7d60-4dfd-a095-db394a92df29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------+----------------+--------------------+--------------------+--------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------------+-------------+-----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+-----------------+------------------+-------------+----------------+\n",
            "|User ID|Interaction ID|       Timestamp|          User Query|     Intent Detected|        Bot Response|Response Time (ms)|Prediction Accuracy (%)|Entity Extraction Accuracy (%)|User Sentiment|    User Feedback|Conversation Success|    User Type|       Region|Device Type|Account Age (months)|Is Premium|               words|            filtered|         rawFeatures|            features|label|       rawPrediction|         probability|prediction|  Adaptive_Action|     Avg_Sentiment|Auto_Escalate|Session_Escalate|\n",
            "+-------+--------------+----------------+--------------------+--------------------+--------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------------+-------------+-----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+-----------------+------------------+-------------+----------------+\n",
            "| U10166|             1|2020-01-28 14:41|What is your pred...|    Financial Advice|Bonds remain a sa...|               150|                     95|                            90|      Positive|          Helpful|          Successful|       Retail|         Asia|     Tablet|                  43|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|           false|\n",
            "| U10030|             2|2020-11-26 11:59|What is your pred...|         Price Check|Forex markets fav...|               155|                     94|                            91|      Negative|Needs improvement|              Failed|       Retail|South America|    Desktop|                   9|     False|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  0.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|0.6666666666666666|        false|            true|\n",
            "| U10253|             3|2021-09-06 17:10|   Any news on Gold?|    Stock Prediction|Investors are flo...|               160|                     93|                            92|      Negative|Needs improvement|              Failed|Institutional|         Asia|     Mobile|                   4|      True|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  0.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|0.6666666666666666|        false|            true|\n",
            "| U10255|             4|2022-09-14 16:14|Should I buy or s...|     Strategy Advice|WTI is showing hi...|               165|                     92|                            93|       Neutral|Needs improvement|              Failed|       Retail|       Europe|     Mobile|                  49|     False|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  1.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|               0.5|        false|            true|\n",
            "| U10085|             5|2023-11-06 11:40|What's the trend ...|     Strategy Advice|Tesla shows bulli...|               170|                     91|                            94|      Negative|Needs improvement|              Failed|       Retail|North America|    Desktop|                  25|     False|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  0.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|1.3333333333333333|        false|            true|\n",
            "| U10228|             6|2023-07-01 12:28|Should I buy or s...|      Forex Analysis|Crypto markets sh...|               175|                     90|                            90|      Positive|          Helpful|          Successful|Institutional|North America|     Mobile|                  51|      True|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               1.5|        false|           false|\n",
            "| U10081|             7|2024-07-13 09:45|    Analysis of Oil?|         Price Check|Oil shows demand ...|               180|                     89|                            91|      Positive|          Helpful|          Successful|       Retail|         Asia|    Desktop|                  44|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|           false|\n",
            "| U10271|             8|2021-04-09 10:36|What's the price ...|Cryptocurrency Up...|GBP trends show m...|               185|                     88|                            92|      Positive|          Helpful|          Successful|Institutional|       Europe|     Tablet|                  37|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|           false|\n",
            "| U10044|             9|2020-09-06 14:20|Should I buy or s...|     Market Analysis|ETH is showing a ...|               190|                     87|                            93|      Positive|          Helpful|          Successful|Institutional|       Africa|     Tablet|                  55|      True|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               1.2|        false|           false|\n",
            "| U10131|            10|2021-08-04 13:42|Give me an update...| Investment Planning|USD is strengthen...|               195|                     86|                            94|      Positive|          Helpful|          Successful|       Retail|       Europe|     Mobile|                  57|      True|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               1.6|        false|           false|\n",
            "| U10283|            11|2023-09-21 14:38|What's the price ...|         Price Check|Tesla shows bulli...|               150|                     95|                            90|      Positive|          Helpful|          Successful|       Retail|       Europe|     Mobile|                  55|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|1.3333333333333333|        false|           false|\n",
            "| U10066|            12|2023-10-13 10:22|What is your pred...|    Stock Prediction| USD remains stable.|               155|                     94|                            91|       Neutral|Needs improvement|              Failed|Institutional|       Africa|     Mobile|                  54|     False|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  1.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|               1.0|        false|            true|\n",
            "| U10135|            13|2022-08-20 11:52|What's the trend ...|     Strategy Advice|Oil prices are ri...|               160|                     93|                            92|      Positive|          Helpful|          Successful|Institutional|       Europe|     Mobile|                  23|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|           false|\n",
            "| U10104|            14|2022-10-19 10:43|What's your take ...|           Buy Order|GOOGL stock is sl...|               165|                     92|                            93|      Positive|          Helpful|          Successful|       Retail|       Europe|     Mobile|                  27|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               1.0|        false|           false|\n",
            "| U10008|            15|2021-06-04 12:19|Market outlook fo...|      Forex Analysis|ETH is showing a ...|               170|                     91|                            94|      Negative|Needs improvement|              Failed|Institutional|         Asia|    Desktop|                  37|      True|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  0.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|               1.0|        false|            true|\n",
            "| U10015|            16|2020-03-12 11:32|Market outlook fo...|   Future Investment|NASDAQ shows inve...|               175|                     90|                            90|      Positive|          Helpful|          Successful|       Retail|       Europe|     Mobile|                  37|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|           false|\n",
            "| U10150|            17|2023-07-20 11:36|What's the trend ...|    Stock Prediction|Crypto markets sh...|               180|                     89|                            91|      Negative|Needs improvement|              Failed|       Retail|North America|     Mobile|                  36|      True|[needs, improvement]|[needs, improvement]|(1000,[678,740],[...|(1000,[678,740],[...|  0.0|[3.20192015077557...|[0.74800474681420...|       0.0|Simplify Response|1.3333333333333333|        false|            true|\n",
            "| U10070|            18|2023-07-06 16:40|Market outlook fo...|          Sell Order|Oil shows demand ...|               185|                     88|                            92|      Positive|          Helpful|          Successful|Institutional|North America|     Tablet|                  56|      True|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               2.0|        false|           false|\n",
            "| U10298|            19|2024-12-21 11:35|Market outlook fo...|     Market Analysis|GOOGL remains a s...|               190|                     87|                            93|      Positive|          Helpful|          Successful|       Retail|         Asia|     Tablet|                  53|      True|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|0.6666666666666666|        false|           false|\n",
            "| U10112|            20|2021-08-10 11:11|What's the trend ...|    Stock Prediction|MSFT outlook is p...|               195|                     86|                            94|      Positive|          Helpful|          Successful|       Retail|North America|     Mobile|                  14|     False|           [helpful]|           [helpful]|  (1000,[286],[1.0])|(1000,[286],[0.51...|  2.0|[-2.8805642237162...|[1.39938496069080...|       2.0|        No Change|               1.5|        false|           false|\n",
            "+-------+--------------+----------------+--------------------+--------------------+--------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------------+-------------+-----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+-----------------+------------------+-------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show only sessions where escalation is needed at session-level\n",
        "final_output.filter(col(\"Session_Escalate\") == True).show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydlrNZ6FSlpm",
        "outputId": "feb68638-ab9d-4b4a-ca05-0f1227d05589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------+----------------+----------------------------------+-----------------+--------------------------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------------+-------------+-----------+--------------------+----------+--------------------+--------------------+--------------------------+--------------------------------------------------------+-----+--------------------------------------------------------+-------------------------------------------------------------+----------+-----------------+------------------+-------------+----------------+\n",
            "|User ID|Interaction ID|Timestamp       |User Query                        |Intent Detected  |Bot Response                          |Response Time (ms)|Prediction Accuracy (%)|Entity Extraction Accuracy (%)|User Sentiment|User Feedback    |Conversation Success|User Type    |Region       |Device Type|Account Age (months)|Is Premium|words               |filtered            |rawFeatures               |features                                                |label|rawPrediction                                           |probability                                                  |prediction|Adaptive_Action  |Avg_Sentiment     |Auto_Escalate|Session_Escalate|\n",
            "+-------+--------------+----------------+----------------------------------+-----------------+--------------------------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------------+-------------+-----------+--------------------+----------+--------------------+--------------------+--------------------------+--------------------------------------------------------+-----+--------------------------------------------------------+-------------------------------------------------------------+----------+-----------------+------------------+-------------+----------------+\n",
            "|U10030 |2             |2020-11-26 11:59|What is your prediction for Forex?|Price Check      |Forex markets favor USD today.        |155               |94                     |91                            |Negative      |Needs improvement|Failed              |Retail       |South America|Desktop    |9                   |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|0.6666666666666666|false        |true            |\n",
            "|U10253 |3             |2021-09-06 17:10|Any news on Gold?                 |Stock Prediction |Investors are flocking to Gold.       |160               |93                     |92                            |Negative      |Needs improvement|Failed              |Institutional|Asia         |Mobile     |4                   |True      |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|0.6666666666666666|false        |true            |\n",
            "|U10255 |4             |2022-09-14 16:14|Should I buy or sell WTI?         |Strategy Advice  |WTI is showing high volatility.       |165               |92                     |93                            |Neutral       |Needs improvement|Failed              |Retail       |Europe       |Mobile     |49                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|1.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|0.5               |false        |true            |\n",
            "|U10085 |5             |2023-11-06 11:40|What's the trend with Tesla?      |Strategy Advice  |Tesla shows bullish signs.            |170               |91                     |94                            |Negative      |Needs improvement|Failed              |Retail       |North America|Desktop    |25                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|1.3333333333333333|false        |true            |\n",
            "|U10066 |12            |2023-10-13 10:22|What is your prediction for USD?  |Stock Prediction |USD remains stable.                   |155               |94                     |91                            |Neutral       |Needs improvement|Failed              |Institutional|Africa       |Mobile     |54                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|1.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|1.0               |false        |true            |\n",
            "|U10008 |15            |2021-06-04 12:19|Market outlook for ETH?           |Forex Analysis   |ETH is showing a downward trend.      |170               |91                     |94                            |Negative      |Needs improvement|Failed              |Institutional|Asia         |Desktop    |37                  |True      |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|1.0               |false        |true            |\n",
            "|U10150 |17            |2023-07-20 11:36|What's the trend with Crypto?     |Stock Prediction |Crypto markets show mixed performance.|180               |89                     |91                            |Negative      |Needs improvement|Failed              |Retail       |North America|Mobile     |36                  |True      |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|1.3333333333333333|false        |true            |\n",
            "|U10279 |22            |2022-01-16 11:12|How is GBP trending today?        |Risk Analysis    |GBP is gaining against EUR.           |155               |94                     |91                            |Negative      |Needs improvement|Failed              |Institutional|Africa       |Mobile     |42                  |True      |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|0.0               |true         |true            |\n",
            "|U10041 |26            |2021-05-02 13:14|Analysis of Equities?             |Financial Advice |Equity markets are stabilizing.       |175               |90                     |90                            |Neutral       |Needs improvement|Failed              |Institutional|North America|Mobile     |35                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|1.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|1.0               |false        |true            |\n",
            "|U10248 |28            |2023-09-17 10:36|What's the price of Forex now?    |Future Investment|Forex shows balanced trading.         |185               |88                     |92                            |Negative      |Needs improvement|Failed              |Institutional|Asia         |Desktop    |43                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|0.0               |true         |true            |\n",
            "|U10041 |30            |2022-09-27 09:48|What's your take on AAPL?         |Sell Order       |AAPL earnings beat expectations.      |195               |86                     |94                            |Negative      |Needs improvement|Failed              |Institutional|North America|Mobile     |35                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|1.0               |false        |true            |\n",
            "|U10023 |34            |2020-04-07 14:55|What is your prediction for GOOGL?|Buy Order        |GOOGL remains a solid long-term pick. |165               |92                     |93                            |Negative      |Needs improvement|Failed              |Institutional|Europe       |Mobile     |11                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|0.8               |false        |true            |\n",
            "|U10076 |35            |2024-11-14 11:39|What's your take on NASDAQ?       |Market Analysis  |NASDAQ shows investor optimism.       |170               |91                     |94                            |Negative      |Needs improvement|Failed              |Retail       |Middle East  |Tablet     |18                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|0.6666666666666666|false        |true            |\n",
            "|U10158 |39            |2022-05-19 13:54|Market outlook for Tesla?         |Buy Order        |Tesla shows bullish signs.            |190               |87                     |93                            |Negative      |Needs improvement|Failed              |Retail       |Middle East  |Desktop    |39                  |True      |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|0.8               |false        |true            |\n",
            "|U10033 |40            |2024-11-27 10:08|Market outlook for XAU?           |Strategy Advice  |Gold prices are increasing.           |195               |86                     |94                            |Neutral       |Needs improvement|Failed              |Retail       |South America|Mobile     |58                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|1.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|1.0               |false        |true            |\n",
            "|U10086 |41            |2023-01-09 11:44|Should I diversify with BTC?      |Trading Bot Query|BTC is bullish, buying recommended.   |150               |95                     |90                            |Negative      |Needs improvement|Failed              |VIP          |Asia         |Mobile     |36                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|1.6666666666666667|false        |true            |\n",
            "|U10014 |43            |2021-11-13 16:09|Analysis of Bonds?                |Financial Advice |Bond yields are increasing.           |160               |93                     |92                            |Negative      |Needs improvement|Failed              |Retail       |South America|Mobile     |53                  |True      |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|1.0               |false        |true            |\n",
            "|U10179 |49            |2020-09-13 12:27|What's the trend with AAPL?       |Strategy Advice  |AAPL stock remains steady.            |190               |87                     |93                            |Negative      |Needs improvement|Failed              |VIP          |Middle East  |Tablet     |16                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|1.0               |false        |true            |\n",
            "|U10154 |51            |2022-06-18 11:36|What's your take on AAPL?         |Strategy Advice  |AAPL stock remains steady.            |150               |95                     |90                            |Negative      |Needs improvement|Failed              |Retail       |North America|Mobile     |10                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|0.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|1.6               |false        |true            |\n",
            "|U10072 |52            |2023-06-22 09:02|What's your take on XAU?          |Forex Analysis   |Gold prices are increasing.           |155               |94                     |91                            |Neutral       |Needs improvement|Failed              |Retail       |Africa       |Desktop    |56                  |False     |[needs, improvement]|[needs, improvement]|(1000,[678,740],[1.0,1.0])|(1000,[678,740],[0.9147933520086514,0.9147933520086514])|1.0  |[3.201920150775571,2.113327220301393,-5.315247371076964]|[0.7480047468142033,0.2518456483961935,1.4960478960322868E-4]|0.0       |Simplify Response|0.75              |false        |true            |\n",
            "+-------+--------------+----------------+----------------------------------+-----------------+--------------------------------------+------------------+-----------------------+------------------------------+--------------+-----------------+--------------------+-------------+-------------+-----------+--------------------+----------+--------------------+--------------------+--------------------------+--------------------------------------------------------+-----+--------------------------------------------------------+-------------------------------------------------------------+----------+-----------------+------------------+-------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter escalated sessions needing improvement\n",
        "sessions_to_improve = final_output.filter(\n",
        "    (col(\"Auto_Escalate\") == True) | (col(\"Session_Escalate\") == True)\n",
        ").select(\n",
        "    \"Interaction ID\", \"User ID\", \"User Query\", \"Bot Response\", \"User Sentiment\",\n",
        "    \"User Feedback\", \"Adaptive_Action\"\n",
        ")\n",
        "\n",
        "sessions_to_improve.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EB6znaVSpFA",
        "outputId": "49246b01-bc58-41f3-e121-9187ed852d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------+----------------------------------+--------------------------------------+--------------+-----------------+-----------------+\n",
            "|Interaction ID|User ID|User Query                        |Bot Response                          |User Sentiment|User Feedback    |Adaptive_Action  |\n",
            "+--------------+-------+----------------------------------+--------------------------------------+--------------+-----------------+-----------------+\n",
            "|2             |U10030 |What is your prediction for Forex?|Forex markets favor USD today.        |Negative      |Needs improvement|Simplify Response|\n",
            "|3             |U10253 |Any news on Gold?                 |Investors are flocking to Gold.       |Negative      |Needs improvement|Simplify Response|\n",
            "|4             |U10255 |Should I buy or sell WTI?         |WTI is showing high volatility.       |Neutral       |Needs improvement|Simplify Response|\n",
            "|5             |U10085 |What's the trend with Tesla?      |Tesla shows bullish signs.            |Negative      |Needs improvement|Simplify Response|\n",
            "|12            |U10066 |What is your prediction for USD?  |USD remains stable.                   |Neutral       |Needs improvement|Simplify Response|\n",
            "|15            |U10008 |Market outlook for ETH?           |ETH is showing a downward trend.      |Negative      |Needs improvement|Simplify Response|\n",
            "|17            |U10150 |What's the trend with Crypto?     |Crypto markets show mixed performance.|Negative      |Needs improvement|Simplify Response|\n",
            "|22            |U10279 |How is GBP trending today?        |GBP is gaining against EUR.           |Negative      |Needs improvement|Simplify Response|\n",
            "|26            |U10041 |Analysis of Equities?             |Equity markets are stabilizing.       |Neutral       |Needs improvement|Simplify Response|\n",
            "|28            |U10248 |What's the price of Forex now?    |Forex shows balanced trading.         |Negative      |Needs improvement|Simplify Response|\n",
            "|30            |U10041 |What's your take on AAPL?         |AAPL earnings beat expectations.      |Negative      |Needs improvement|Simplify Response|\n",
            "|34            |U10023 |What is your prediction for GOOGL?|GOOGL remains a solid long-term pick. |Negative      |Needs improvement|Simplify Response|\n",
            "|35            |U10076 |What's your take on NASDAQ?       |NASDAQ shows investor optimism.       |Negative      |Needs improvement|Simplify Response|\n",
            "|39            |U10158 |Market outlook for Tesla?         |Tesla shows bullish signs.            |Negative      |Needs improvement|Simplify Response|\n",
            "|40            |U10033 |Market outlook for XAU?           |Gold prices are increasing.           |Neutral       |Needs improvement|Simplify Response|\n",
            "|41            |U10086 |Should I diversify with BTC?      |BTC is bullish, buying recommended.   |Negative      |Needs improvement|Simplify Response|\n",
            "|43            |U10014 |Analysis of Bonds?                |Bond yields are increasing.           |Negative      |Needs improvement|Simplify Response|\n",
            "|49            |U10179 |What's the trend with AAPL?       |AAPL stock remains steady.            |Negative      |Needs improvement|Simplify Response|\n",
            "|51            |U10154 |What's your take on AAPL?         |AAPL stock remains steady.            |Negative      |Needs improvement|Simplify Response|\n",
            "|52            |U10072 |What's your take on XAU?          |Gold prices are increasing.           |Neutral       |Needs improvement|Simplify Response|\n",
            "+--------------+-------+----------------------------------+--------------------------------------+--------------+-----------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sessions_to_improve.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saDhT0NtStOk",
        "outputId": "41f6a43c-8c29-454f-f6e5-479c35d3027b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Interaction ID', 'User ID', 'User Query', 'Bot Response', 'User Sentiment', 'User Feedback', 'Adaptive_Action']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Select relevant columns: user queries and current bot responses\n",
        "sessions_for_review = sessions_to_improve.select(\"User Query\", \"Bot Response\")\n",
        "\n",
        "# Step 2: Convert to Pandas DataFrame\n",
        "pandas_review_df = sessions_for_review.toPandas()\n",
        "\n",
        "# Step 3: Add a blank column for suggested improved responses\n",
        "pandas_review_df[\"Improved Bot Response Suggestion\"] = \"\"\n",
        "\n",
        "# Step 4: Save to CSV for manual review\n",
        "output_path = r'bot_response_review_new.csv'\n",
        "pandas_review_df.to_csv(output_path, index=False)\n",
        "\n",
        "# Step 5: Notify\n",
        "print(f\"✅ CSV created for bot response improvement at:\\n{output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOevmka0SwNb",
        "outputId": "ef73a541-e24f-4024-bb2a-6ac8f42a6ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV created for bot response improvement at:\n",
            "bot_response_review_new.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1: Load Data with PySpark\n",
        "#python\n",
        "#CopyEdit\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ImprovedBotResponse\").getOrCreate()\n",
        "\n",
        "csv_path = r'/content/bot_response_review_new.csv'\n",
        "df = spark.read.option(\"header\", True).csv(csv_path)\n",
        "df.printSchema()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWJfc4ZYS5tb",
        "outputId": "6b6d7f22-e2ae-41fb-fa77-b7d4b6aafbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- User Query: string (nullable = true)\n",
            " |-- Bot Response: string (nullable = true)\n",
            " |-- Improved Bot Response Suggestion: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#🔁 Step 2: Convert to Pandas\n",
        "#python\n",
        "#CopyEdit\n",
        "# Convert to Pandas for transformer use\n",
        "pandas_df = df.toPandas()"
      ],
      "metadata": {
        "id": "yYBZFem8TC66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#🤖 Step 3: Use Hugging Face Transformers to Improve Responses\n",
        "#We'll use transformers library (like t5-small or gpt2) to rephrase or improve bot responses given the query.\n",
        "#Install required packages first:\n",
        "#bash\n",
        "#CopyEdit\n",
        "!pip install transformers sentencepiece\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuhxS7j9TGRo",
        "outputId": "45a1259b-d53b-41ed-b671-7841fe9e0e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# After installation, restart your runtime (Runtime > Restart runtime),\n",
        "# then run the following code.\n",
        "\n",
        "#  Import and load the paraphrasing model with improved sampling logic\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Load the paraphrasing model\n",
        "rephrase_pipeline = pipeline(\"text2text-generation\", model=\"Vamsi/T5_Paraphrase_Paws\")\n",
        "\n",
        "def improve_response(query, bot_response):\n",
        "    if not bot_response or not isinstance(bot_response, str):\n",
        "        return \"\"\n",
        "\n",
        "    input_text = f\"paraphrase: {bot_response} </s>\"\n",
        "\n",
        "    # Generate multiple paraphrases using sampling to encourage variation\n",
        "    outputs = rephrase_pipeline(\n",
        "        input_text,\n",
        "        max_length=60,\n",
        "        num_return_sequences=3,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.9,\n",
        "        clean_up_tokenization_spaces=True\n",
        "    )\n",
        "\n",
        "    # Return the first paraphrase that is different from original\n",
        "    for out in outputs:\n",
        "        candidate = out['generated_text'].strip()\n",
        "        if candidate.lower() != bot_response.strip().lower():\n",
        "            return candidate\n",
        "\n",
        "    # If none different, append note to original\n",
        "    return bot_response + \" (Rephrased)\"\n",
        "\n",
        "#  Load your CSV dataset into Pandas\n",
        "csv_path = '/content/bot_response_review_new.csv'  # <-- change this to your file path\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "#  Apply the paraphrasing function to all rows\n",
        "df[\"Improved Bot Response\"] = df.apply(\n",
        "    lambda row: improve_response(row[\"User Query\"], row[\"Bot Response\"]),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "#  Save the updated DataFrame to a new CSV file\n",
        "output_path = '/content/bot_response_review.csv'  # change as needed\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"✅ Improved responses saved to {output_path}\")\n",
        "\n",
        "# Optional: display the first few rows to verify\n",
        "print(df[[\"User Query\", \"Bot Response\", \"Improved Bot Response\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5761VDxqdHHb",
        "outputId": "2b3818ce-553f-4fe3-9bfa-68cddd9b156d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Improved responses saved to /content/bot_response_review.csv\n",
            "                           User Query                     Bot Response  \\\n",
            "0  What is your prediction for Forex?   Forex markets favor USD today.   \n",
            "1                   Any news on Gold?  Investors are flocking to Gold.   \n",
            "2           Should I buy or sell WTI?  WTI is showing high volatility.   \n",
            "3        What's the trend with Tesla?       Tesla shows bullish signs.   \n",
            "4    What is your prediction for USD?              USD remains stable.   \n",
            "\n",
            "                 Improved Bot Response  \n",
            "0  Today, the Forex markets favor USD.  \n",
            "1             Investors flock to gold.  \n",
            "2           WTI shows high volatility.  \n",
            "3        Tesla displays bullish signs.  \n",
            "4              The USD remains stable.  \n"
          ]
        }
      ]
    }
  ]
}